{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "True_news = pd.read_csv('True.csv')\n",
    "Fake_news = pd.read_csv('Fake.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "True_news['label'] = 0\n",
    "Fake_news['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = True_news[['text', 'label']]\n",
    "dataset2 = Fake_news[['text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df=pd.concat([dataset1 ,dataset2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Not long ago, Rep. Jason Chaffetz (R-Utah), sa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>According to a new report, health insurance pr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>The Congressional Budget Office released their...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Donald Trump was in a room full of Irish repor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Donald Trump s war on the free press just ente...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "0    WASHINGTON (Reuters) - The head of a conservat...      0\n",
       "1    WASHINGTON (Reuters) - Transgender people will...      0\n",
       "2    WASHINGTON (Reuters) - The special counsel inv...      0\n",
       "3    WASHINGTON (Reuters) - Trump campaign adviser ...      0\n",
       "4    SEATTLE/WASHINGTON (Reuters) - President Donal...      0\n",
       "..                                                 ...    ...\n",
       "995  Not long ago, Rep. Jason Chaffetz (R-Utah), sa...      1\n",
       "996  According to a new report, health insurance pr...      1\n",
       "997  The Congressional Budget Office released their...      1\n",
       "998  Donald Trump was in a room full of Irish repor...      1\n",
       "999  Donald Trump s war on the free press just ente...      1\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.5\n",
      "Median: 0.5\n",
      "Mode: 0 (occurs 1000 times)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "label_mean = combined_df['label'].mean()\n",
    "label_median = combined_df['label'].median()\n",
    "label_mode_result = stats.mode(combined_df['label'])\n",
    "\n",
    "# Access mode and its count directly without indexing\n",
    "label_mode = label_mode_result.mode\n",
    "label_mode_count = label_mode_result.count\n",
    "\n",
    "print(f\"Mean: {label_mean}\")\n",
    "print(f\"Median: {label_median}\")\n",
    "print(f\"Mode: {label_mode} (occurs {label_mode_count} times)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: inf\n",
      "P-value: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_10604\\3220037983.py:2: ConstantInputWarning: Each of the input arrays is constant; the F statistic is not defined or infinite\n",
      "  f_statistic, p_value = stats.f_oneway(combined_df[combined_df['label'] == 0]['label'],\n"
     ]
    }
   ],
   "source": [
    "# Perform ANOVA F-test\n",
    "f_statistic, p_value = stats.f_oneway(combined_df[combined_df['label'] == 0]['label'],\n",
    " combined_df[combined_df['label'] == 1]['label'])\n",
    "print(f\"F-statistic: {f_statistic}\")\n",
    "print(f\"P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'text_length' with the length of the 'text' column\n",
    "combined_df['text_length'] = combined_df['text'].apply(lambda x: len(x.split()))\n",
    "# Separate text lengths for the two groups\n",
    "true_text_length = combined_df[combined_df['label'] == 0]['text_length']\n",
    "fake_text_length = combined_df[combined_df['label'] == 1]['text_length']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: -2.5639058981394967\n",
      "P-value: 0.01042271414679376\n"
     ]
    }
   ],
   "source": [
    "# Perform an independent t-test\n",
    "t_statistic, p_value = stats.ttest_ind(true_text_length, fake_text_length)\n",
    "print(f\"T-statistic: {t_statistic}\")\n",
    "print(f\"P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-squared statistic: 1996.002\n",
      "P-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "# Replace \"Your_Categorical_Variable\" with the actual categorical variable name\n",
    "categorical_variable ='label'\n",
    "# Create a contingency table to assess the association between 'label' and the categorical variable\n",
    "contingency_table = pd.crosstab(combined_df['label'], combined_df[categorical_variable])\n",
    "# Perform a chi-squared test\n",
    "chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "print(f\"Chi-squared statistic: {chi2}\")\n",
    "print(f\"P-value: {p}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            text_length   R-squared:                       0.003\n",
      "Model:                            OLS   Adj. R-squared:                  0.003\n",
      "Method:                 Least Squares   F-statistic:                     6.574\n",
      "Date:                Wed, 07 Feb 2024   Prob (F-statistic):             0.0104\n",
      "Time:                        00:14:40   Log-Likelihood:                -13564.\n",
      "No. Observations:                2000   AIC:                         2.713e+04\n",
      "Df Residuals:                    1998   BIC:                         2.714e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        393.4860      6.751     58.282      0.000     380.245     406.727\n",
      "label         24.4800      9.548      2.564      0.010       5.755      43.205\n",
      "==============================================================================\n",
      "Omnibus:                      300.753   Durbin-Watson:                   1.902\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              541.149\n",
      "Skew:                           0.951   Prob(JB):                    3.10e-118\n",
      "Kurtosis:                       4.696   Cond. No.                         2.62\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "# Specify the independent variable (label) and dependent variable (word count)\n",
    "X = combined_df[['label']] # Independent variable\n",
    "y = combined_df['text_length'] # Dependent variable\n",
    "# Add a constant term to the independent variable (intercept)\n",
    "X = sm.add_constant(X)\n",
    "# Fit a linear regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "# Get the regression summary\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.52\n",
      "Confusion Matrix:\n",
      "[[125  74]\n",
      " [118  83]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.63      0.57       199\n",
      "           1       0.53      0.41      0.46       201\n",
      "\n",
      "    accuracy                           0.52       400\n",
      "   macro avg       0.52      0.52      0.51       400\n",
      "weighted avg       0.52      0.52      0.51       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "# Specify the independent variables (features) and the target variable (label)\n",
    "X = combined_df[['text_length']] # Replace with your feature columns\n",
    "y = combined_df['label'] # Target variable\n",
    "# Split the data into a training set and a testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "random_state=42)\n",
    "# Initialize and fit the logistic regression model\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "# Make predictions on the testing set\n",
    "y_pred = logistic_regression.predict(X_test)\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion}\")\n",
    "print(f\"Classification Report:\\n{classification_rep}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6825\n",
      "Confusion Matrix:\n",
      "[[132  67]\n",
      " [ 60 141]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.66      0.68       199\n",
      "           1       0.68      0.70      0.69       201\n",
      "\n",
      "    accuracy                           0.68       400\n",
      "   macro avg       0.68      0.68      0.68       400\n",
      "weighted avg       0.68      0.68      0.68       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "# Initialize and fit the decision tree classifier\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "# Make predictions on the testing set\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion}\")\n",
    "print(f\"Classification Report:\\n{classification_rep}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7025\n",
      "Confusion Matrix:\n",
      "[[128  71]\n",
      " [ 48 153]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.64      0.68       199\n",
      "           1       0.68      0.76      0.72       201\n",
      "\n",
      "    accuracy                           0.70       400\n",
      "   macro avg       0.71      0.70      0.70       400\n",
      "weighted avg       0.71      0.70      0.70       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Initialize and fit the Random Forest classifier\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "# Make predictions on the testing set\n",
    "y_pred = random_forest.predict(X_test)\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion}\")\n",
    "print(f\"Classification Report:\\n{classification_rep}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6975\n",
      "Confusion Matrix:\n",
      "[[123  76]\n",
      " [ 45 156]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.62      0.67       199\n",
      "           1       0.67      0.78      0.72       201\n",
      "\n",
      "    accuracy                           0.70       400\n",
      "   macro avg       0.70      0.70      0.70       400\n",
      "weighted avg       0.70      0.70      0.70       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Initialize and fit the K-NN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5) # You can adjust the number of neighbors (k) as needed\n",
    "knn.fit(X_train, y_train)\n",
    "# Make predictions on the testing set\n",
    "y_pred = knn.predict(X_test)\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion}\")\n",
    "print(f\"Classification Report:\\n{classification_rep}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.555\n",
      "Confusion Matrix:\n",
      "[[100  99]\n",
      " [ 79 122]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.50      0.53       199\n",
      "           1       0.55      0.61      0.58       201\n",
      "\n",
      "    accuracy                           0.56       400\n",
      "   macro avg       0.56      0.55      0.55       400\n",
      "weighted avg       0.56      0.56      0.55       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "# Initialize and fit the SVM classifier\n",
    "svm_classifier = SVC(kernel='linear') # You can choose different kernels such as 'linear', 'rbf', or 'poly'\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "# Make predictions on the testing set\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion}\")\n",
    "print(f\"Classification Report:\\n{classification_rep}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# Build the ANN model\n",
    "max_words=10000\n",
    "max_sequence_length=10000\n",
    "model = keras.Sequential([\n",
    " keras.layers.Embedding(input_dim=max_words, output_dim=16, \n",
    "input_length=max_sequence_length),\n",
    " keras.layers.Flatten(),\n",
    " keras.layers.Dense(64, activation='relu'),\n",
    " keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, \n",
    "random_state=42)\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_val, \n",
    "y_val))\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Centers:\n",
      "[[0.01044457 0.00928839 0.0038981  ... 0.00573443 0.00301271 0.00202795]\n",
      " [0.00780698 0.00650123 0.00226734 ... 0.05743144 0.00507113 0.01622004]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_10604\\548355031.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset1['cluster_label'] = kmeans.labels_[:len(dataset1)]\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_10604\\548355031.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset2['cluster_label'] = kmeans.labels_[len(dataset1):]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Now you can use TfidfVectorizer in your code\n",
    "combined_text = pd.concat([dataset1['text'], dataset2['text']])\n",
    "# Preprocess the text data using TF-IDF vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000) # Adjust the number of features as needed\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(combined_text)\n",
    "# Perform K-Means clustering\n",
    "num_clusters = 2 # Assuming you want to separate true news and fake news\n",
    "kmeans = KMeans(n_clusters=num_clusters)\n",
    "kmeans.fit(tfidf_matrix)\n",
    "# Add cluster labels to your DataFrames\n",
    "dataset1['cluster_label'] = kmeans.labels_[:len(dataset1)]\n",
    "dataset2['cluster_label'] = kmeans.labels_[len(dataset1):]\n",
    "# Print cluster centers (optional)\n",
    "print(\"Cluster Centers:\")\n",
    "print(kmeans.cluster_centers_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Centers:\n",
      "[[ 5.40786658e-01 -4.66265749e-02  1.92879814e-02  5.87697882e-03\n",
      "  -5.93529014e-03  4.47971295e-03 -1.70942379e-03  1.82507954e-03\n",
      "   3.31031633e-03  2.88937123e-04 -3.62122127e-03  2.13036602e-03\n",
      "   4.02710134e-03  1.36590531e-03 -4.45038919e-04  8.69028429e-04\n",
      "   4.04312643e-04  2.12191232e-03 -3.58221964e-03  1.41873618e-04\n",
      "  -9.49558385e-04  1.47329063e-03  6.85916970e-04  2.67735491e-04\n",
      "   1.38750169e-03  2.60001282e-04  1.81911812e-03  6.23482691e-04\n",
      "   1.33402930e-03  2.20163436e-04 -9.73120878e-04  1.08978424e-03\n",
      "  -1.25261034e-03  7.52321983e-04 -1.70934130e-04  9.83689809e-04\n",
      "   6.68561585e-04  7.41210473e-04 -4.43880152e-04  4.83736231e-04\n",
      "  -8.09727328e-04  4.90164860e-04  1.16691965e-05  1.43432266e-04\n",
      "   5.73090239e-04  4.65113034e-04 -6.48067550e-04  1.02228687e-05\n",
      "   1.10576281e-03  4.30038112e-05]\n",
      " [ 4.87026122e-01  3.50231861e-01 -1.06323219e-01 -1.91418787e-02\n",
      "   7.80511227e-02  1.63582539e-02  1.26394723e-03 -6.95842455e-03\n",
      "   8.69663312e-03  3.26420184e-03 -7.24913756e-03 -2.69532007e-03\n",
      "   1.06106828e-03 -4.90411369e-04 -1.29926097e-02  2.86769258e-03\n",
      "   4.81071278e-03 -7.41451854e-03  6.99512746e-03  1.58241081e-03\n",
      "   4.93654682e-03 -4.79928324e-03 -2.77013474e-03 -7.70627260e-04\n",
      "   1.98432200e-03 -1.44041919e-03 -9.56937766e-03  7.03691935e-03\n",
      "  -8.28070250e-03  3.46332136e-04  1.66055926e-03  3.29814112e-03\n",
      "   5.34744569e-03  2.47047580e-04  3.53246703e-04 -9.54308630e-06\n",
      "  -5.88832270e-03 -5.07407366e-04 -2.72610565e-03  2.63249973e-03\n",
      "   1.19427133e-03  3.13318151e-03 -1.51422626e-03  4.29124592e-03\n",
      "  -4.56897254e-04  7.62558921e-04 -2.96365750e-04  7.75231317e-04\n",
      "  -5.70917672e-03 -9.01466444e-04]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_10604\\2025213584.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset1['cluster_label'] = kmeans.labels_[:len(dataset1)]\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_10604\\2025213584.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset2['cluster_label'] = kmeans.labels_[len(dataset1):]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "# Preprocess the text data using TF-IDF vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000) # Adjust the number of features as needed\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(combined_text)\n",
    "# Perform Truncated SVD (PCA alternative) to reduce dimensionality\n",
    "n_components = 50 # Number of components to retain\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "tfidf_svd = svd.fit_transform(tfidf_matrix)\n",
    "# Perform K-Means clustering on the SVD-transformed data\n",
    "num_clusters = 2 # Assuming you want to separate true news and fake news\n",
    "kmeans = KMeans(n_clusters=num_clusters)\n",
    "kmeans.fit(tfidf_svd)\n",
    "# Add cluster labels to your DataFrames\n",
    "dataset1['cluster_label'] = kmeans.labels_[:len(dataset1)]\n",
    "dataset2['cluster_label'] = kmeans.labels_[len(dataset1):]\n",
    "# Print cluster centers (optional)\n",
    "print(\"Cluster Centers:\")\n",
    "print(kmeans.cluster_centers_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.1288050372823802\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "silhouette_avg = silhouette_score(tfidf_svd, kmeans.labels_)\n",
    "print(f\"Silhouette Score: {silhouette_avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inertia: 491.1639596644791\n"
     ]
    }
   ],
   "source": [
    "inertia = kmeans.inertia_\n",
    "print(f\"Inertia: {inertia}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3765\n",
      "Confusion Matrix:\n",
      " [[746 254]\n",
      " [993   7]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.75      0.54      1000\n",
      "           1       0.03      0.01      0.01      1000\n",
      "\n",
      "    accuracy                           0.38      2000\n",
      "   macro avg       0.23      0.38      0.28      2000\n",
      "weighted avg       0.23      0.38      0.28      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "# Create true labels based on your domain knowledge\n",
    "true_labels = [0] * len(dataset1) + [1] * len(dataset2)\n",
    "accuracy = accuracy_score(true_labels, kmeans.labels_)\n",
    "confusion = confusion_matrix(true_labels, kmeans.labels_)\n",
    "report = classification_report(true_labels, kmeans.labels_)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\\n\", confusion)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
